SERVICE: # Relevant only when using the Qiskit runtime service
  CHANNEL: "ibm_quantum"
  INSTANCE: "ibm-q-nus/default/default"

RUNTIME_OPTIONS: # Relevant only when using the Qiskit runtime service
  optimization_level: 0
  resilience_level: null
  max_execution_time: null
  execution:
    init_qubits: True
    rep_delay: null
  resilience:
    measure_mitigation: null
    measure_noise_learning:
      num_randomizations: null
      shots_per_randomization: null
    zne_mitigation: False
    zne:
      noise_factors: null
      extrapolator: null
    pec_mitigation: False
    pec:
      max_overhead: null
      noise_gain: null
    layer_noise_learning:
      max_layers_to_learn: null
      shots_per_randomization: null
      num_randomizations: null
      layer_pair_depths: null
  environment:
    log_level: "WARNING"
    job_tags: null

BACKEND: # Backend configuration (If all set to null, the user needs to specify its own backend in q_env_config.py's get_backend() function)
  REAL_BACKEND: null # False # True: real or False: fake Aer backend
  NAME: null # "fake_jakarta" # Name of the backend
  DYNAMICS: # Use a DynamicsBackend (if fields above are not null, build a DynamicsBackend.from_backend() with the specified backend)
    USE_DYNAMICS: null # Whether to use a DynamicsBackend
    PHYSICAL_QUBITS: null # Number of qubits characterizing the environment (i.e. the full quantum circuit dimension)
    SOLVER_OPTIONS: # Solver options for the DynamicsBackend
      method: null
      atol: null
      rtol: null
      hmax: null # Maximum step size, if 'auto' the solver will automatically determine the step size with backend.dt
    CALIBRATION_FILES: null

TARGET: # Target Gate configuration
  GATE: "CX"
  # STATE: "0" # Target state (if GATE is null)
  PHYSICAL_QUBITS: [ 0, 1 ]

ENV: # Environment configuration
  EXECUTION:
    SAMPLING_PAULIS: 100 # Number of Pauli strings to sample
    N_SHOTS: 1024 # Number of shots for each Pauli
    N_REPS: 1 # Number of repetitions for the fidelity benchmarking
    C_FACTOR: 1. # Cost factor for the reward function
    BATCH_SIZE: 256 # Number of actions to evaluate per policy iteration
    SEED: 100
  ACTION_SPACE:
    LOW: [ -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1 ]
    HIGH: [ 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1 ]
  REWARD:
    REWARD_METHOD: "state" # Choose between "fidelity", "state", "channel", "xeb", "cafe"
  REWARD_PARAMS: # All unused parameters should be set to null (only assign values to parameters used by chosen reward method)
    NUM_SEQUENCES: null # Number of random sequences to generate for ORBIT or XEB reward
    DEPTH: null # Circuit depth for the random sequences in ORBIT or XEB reward
    USE_INTERLEAVED: null # Whether to use interleaved RB (target must be Clifford) for ORBIT reward
    NUM_EIGENSTATES_PER_PAULI: null # Number of eigenstates per Pauli to consider for channel fidelity reward
    INPUT_STATES_CHOICE: null # Choice of input states for CAFE reward
  BENCHMARKING:
    BENCHMARK_CYCLE: 1 # Number of steps between two fidelity benchmarks
    BENCHMARK_BATCH_SIZE: 1 # Number of actions to evaluate per fidelity benchmark
    CHECK_ON_EXP: False # Whether to perform fidelity benchmarking with tomographic experiments or just using simulation
    TOMOGRAPHY_ANALYSIS: "default" # Analysis method for tomography experiment
    DFE_PRECISION: (1e-3, 1e-3) # Precision tuple (eps, delta) for the DFE analysis
  TRAINING_WITH_CAL: True


